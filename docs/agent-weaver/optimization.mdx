---
description: Cut token spend and response time without sacrificing quality.
keywords:
  - SmythOS
  - Weaver
  - cost optimisation
  - latency
  - token budgeting
  - caching
sidebar_position: 9
---
# Optimising LLM Cost & Latency
> **Tokens are tiny pieces of money.**  
> Spend wisely; users click away after 4 s.

<InfoCallout>
**TL;DR:** Trim prompts, cache results, parallelise calls, watch the spend graph.
</InfoCallout>

<Divider/>

## Token Budgeting 101

- **Trim prompts** — move static text to a **Note** component.  
- **Refactor chains** — merge two micro LLM calls into one bigger call.  
- **Switch models** — GPT-4o mini at `$0.15` ≪ GPT-4o at `$2.50` per 1 M input tokens.

<Divider/>

### Caching with the Note Component

```text
Goal: Reuse a 1 K-token system prompt.

Skills:
1. Note (static prompt)
2. GenAI (dynamic portion)

``` 
(GIF placeholder: Note referencing)

<Divider/>

### Parallelism vs Serial
Use Parallel Branch to fan-out API calls:

- Query → [Sentiment, Translate, Summarise] → Merge
- Drop FSleep nodes to stagger heavy loops and avoid rate limits.

<Divider/>
### Rate Limits & Retries
``` json
{
  "max_wait_sec": 60,
  "retry": 3,
  "backoff_sec": 2
}
```
Configure in component settings with no manual loops required.